{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SB-LSTM-RNN + Hyperparameter GridSearch - Percobaan 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jika dipengaruhi oleh enso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pustaka manipulasi data array\n",
    "import numpy as np\n",
    "\n",
    "# pustaka manipulasi data frame\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from pandas import read_excel\n",
    "\n",
    "import random as rm\n",
    "import time as tm\n",
    "\n",
    "# pustaka untuk visualisasi data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "# library normalize data with max-min algorithm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# library algorithm lstm-rnn with keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import RNN\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.optimizers import Adam, Adamax, RMSprop, SGD\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# pustaka untuk visualisasi acf dan pacf\n",
    "import scipy.stats as sc\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# pustaka untuk  evaluasi model prediksi\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed\n",
    "rm.seed(1234)\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Algorithm\n",
    "algorithm = \"LSTM-RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting Algorithm\n",
    "# algorithm = \"GRU-RNN\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Akuisisi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set waktu komputasi\n",
    "start = tm.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/dataset_enso.csv\", parse_dates=[\"acq_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan metadata dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Praproses Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seleksi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jika hotspot dipengaruhi oleh enso\n",
    "data = dataset[[\"hotspot\", \"sst_std\", \"sst_anom\", \"oni_std\", \"oni_anom\", \"soi_std\", \"soi_anom\"]]\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasil seleksi fitur\n",
    "np.round(data[:5],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek dimensi normalisasi\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data train\n",
    "np.round(scaled[:5],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek dimensi normalisasi\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(dataset[\"acq_date\"], np.array(scaled[:,:1]), color=\"tab:blue\", label=\"Hotspot di Sumatera Selatan 2001 - 2023\", linewidth=2.5)\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(\"\", fontsize=14)\n",
    "ax.set_xlabel(\"\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pembagian Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data train\n",
    "train_size = 216\n",
    "\n",
    "# set loc data train\n",
    "train_data = scaled[0:train_size,:]\n",
    "\n",
    "# show data train\n",
    "np.round(train_data[:5],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data test\n",
    "test_size = 60\n",
    "\n",
    "# set loc data test\n",
    "test_data = scaled[train_size:len(scaled),:]\n",
    "\n",
    "# show data test\n",
    "np.round(test_data[:5],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# make a time series plot\n",
    "ax.plot(dataset.iloc[0:len(train_data),0], train_data[:,:1], color=\"tab:blue\", label=\"Data Train\", linewidth=2.5)\n",
    "ax.plot(dataset.iloc[len(train_data):len(dataset),0], test_data[:,:1], color=\"tab:red\", label=\"Data Test\", linewidth=2.5)\n",
    "\n",
    "# make are labels\n",
    "ax.set_title(\"\", fontsize=14)\n",
    "ax.set_xlabel(\"\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True)\n",
    "\n",
    "# show plot time series\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    \n",
    "    # return value\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hasil supervised learning data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set supervised learning for data train\n",
    "reframed_train = series_to_supervised(train_data, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we don't want to predict\n",
    "reframed_train.drop(reframed_train.columns[[8,9,10,11,12,13]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and outputs\n",
    "trainX, trainY = reframed_train.iloc[:, :-1], reframed_train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a dimension dataset after supervised learning\n",
    "print(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hasil supervised learning data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set supervised learning for data test\n",
    "reframed_test = series_to_supervised(test_data, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns we don't want to predict\n",
    "reframed_test.drop(reframed_test.columns[[8,9,10,11,12,13]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and outputs\n",
    "testX, testY = reframed_test.iloc[:, :-1], reframed_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a dimension dataset after supervised learning\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check data train, for result supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_trainX = pd.DataFrame(trainX)\n",
    "temp_trainY = pd.DataFrame(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_train = pd.concat([temp_trainX, temp_trainY], axis=1)\n",
    "hasil_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check data test, for result supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_testX = pd.DataFrame(testX)\n",
    "temp_testY = pd.DataFrame(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_test = pd.concat([temp_testX, temp_testY], axis=1)\n",
    "hasil_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reshape input for samples, time steps, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data train\n",
    "trainX = np.reshape(np.array(trainX), (trainX.shape[0], 1, trainX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data test\n",
    "testX = np.reshape(np.array(testX), (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Hyperparameter GridSearchCV GRU-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function models\n",
    "def get_model(activation='selu', optimizer='sgd', dropout_rate=0.15):\n",
    "\n",
    "    # reset of session model\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    \n",
    "    # # Jika menggunakan SB-LSTM-RNN\n",
    "    model.add(Bidirectional(LSTM(10, activation=activation, return_sequences=True), input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(Bidirectional(LSTM(10, activation=activation, return_sequences=True)))\n",
    "    model.add(Bidirectional(LSTM(10, activation=activation, return_sequences=False)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # the output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # compiling model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"mae\",\n",
    "        metrics=[\n",
    "            tf.keras.metrics.MeanAbsoluteError(),\n",
    "            tf.keras.metrics.MeanSquaredError(),\n",
    "            tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # return value\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating KerasRegressor wrapper for GridSearchCV\n",
    "grid_model = KerasRegressor(model=get_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set param for GridSearch [1]\n",
    "param_grid = {\n",
    "    'model__activation': ['relu', 'selu', 'elu', 'softplus'],\n",
    "    'model__optimizer': ['adam', 'adamax', 'rmsprop', 'sgd'],\n",
    "    'model__dropout_rate': [0.05, 0.1, 0.15, 0.2, 0.25],\n",
    "    'batch_size': [2, 4, 8, 16, 32],\n",
    "    'epochs': [1500],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung jumlah kombinasi\n",
    "total_combinations = len(list(product(*param_grid.values())))\n",
    "print(\"Total kombinasi:\", total_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process a gridsearchCV \n",
    "grid_search = GridSearchCV(estimator=grid_model, param_grid=param_grid, n_jobs=-1, cv=2, verbose=10, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process a gridsearchCV \n",
    "grid_result = grid_search.fit(trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best parameters: %f using %s\\n\" % (grid_search.best_score_, grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the results\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the results\n",
    "result = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"score\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the results\n",
    "result.sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set akhir waktu komputasi \n",
    "end = tm.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses menghitung waktu komputasi\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hasil waktu komputasi\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "37197ad202cea1caf8a636a74cec7c83b945e4f29ac1505900600f740c02611d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
