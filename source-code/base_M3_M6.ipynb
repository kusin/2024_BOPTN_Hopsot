{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## M3 dan M6 - Model Prediksi Titik Panas di Sumatera Selatan 2001 - 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Jika dipengaruhi oleh enso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pustaka manipulasi data array\n",
    "import numpy as np\n",
    "\n",
    "# pustaka manipulasi data frame\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from pandas import read_excel\n",
    "\n",
    "import random as rm\n",
    "import time as tm\n",
    "\n",
    "# pustaka untuk visualisasi data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "# library normalize data with max-min algorithm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# library algorithm lstm-rnn with keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import RNN\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.optimizers import Adam, Adamax, RMSprop, SGD\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# pustaka untuk visualisasi acf dan pacf\n",
    "import scipy.stats as sc\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# pustaka untuk  evaluasi model prediksi\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed\n",
    "rm.seed(1234)\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Setting Algorithm\n",
    "# algorithm = \"LSTM-RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Algorithm\n",
    "algorithm = \"GRU-RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter\n",
    "activation = \"selu\"\n",
    "dropout_rate = 0.25\n",
    "optimizer = \"sgd\"\n",
    "batch_size = 2\n",
    "epochs=1500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Akuisisi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set waktu komputasi\n",
    "start = tm.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/dataset_enso.csv\", parse_dates=[\"acq_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# menampilkan metadata dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Praproses Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Seleksi Fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jika hotspot dipengaruhi oleh enso\n",
    "data = dataset[[\"hotspot\", \"sst_std\", \"sst_anom\", \"oni_std\", \"oni_anom\", \"soi_std\", \"soi_anom\"]]\n",
    "data = data.values\n",
    "\n",
    "# # jika hotspot dipengaruhi oleh enso\n",
    "# data = dataset[[\"hotspot\", \"sst_anom\", \"oni_anom\", \"soi_anom\"]]\n",
    "# data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasil seleksi fitur\n",
    "np.round(data[:5],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek dimensi normalisasi\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show data train\n",
    "np.round(scaled[:5],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek dimensi normalisasi\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(dataset[\"acq_date\"], np.array(scaled[:,:1]), color=\"tab:blue\", label=\"Hotspot di Sumatera Selatan 2001 - 2023\", linewidth=2.5)\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(\"\", fontsize=14)\n",
    "ax.set_xlabel(\"\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pembagian Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data train\n",
    "train_size = 216\n",
    "\n",
    "# set loc data train\n",
    "train_data = scaled[0:train_size,:]\n",
    "\n",
    "# show data train\n",
    "np.round(train_data[:5],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data test\n",
    "test_size = 60\n",
    "\n",
    "# set loc data test\n",
    "test_data = scaled[train_size:len(scaled),:]\n",
    "\n",
    "# show data test\n",
    "np.round(test_data[:5],4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# make a time series plot\n",
    "ax.plot(dataset.iloc[0:len(train_data),0], train_data[:,:1], color=\"tab:blue\", label=\"Data Train\", linewidth=2.5)\n",
    "ax.plot(dataset.iloc[len(train_data):len(dataset),0], test_data[:,:1], color=\"tab:red\", label=\"Data Test\", linewidth=2.5)\n",
    "\n",
    "# make are labels\n",
    "ax.set_title(\"\", fontsize=14)\n",
    "ax.set_xlabel(\"\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True)\n",
    "\n",
    "# show plot time series\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    \n",
    "    # return value\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hasil supervised learning data train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set supervised learning for data train\n",
    "reframed_train = series_to_supervised(train_data, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jika menggunakan anom sst, oni, dan soi.\n",
    "# # drop columns we don't want to predict\n",
    "# reframed_train.drop(reframed_train.columns[[5,6,7]], axis=1, inplace=True)\n",
    "\n",
    "# Jika menggunakan semua parameter\n",
    "# drop columns we don't want to predict\n",
    "reframed_train.drop(reframed_train.columns[[8,9,10,11,12,13]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and outputs\n",
    "trainX, trainY = reframed_train.iloc[:, :-1], reframed_train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a dimension dataset after supervised learning\n",
    "print(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hasil supervised learning data test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set supervised learning for data test\n",
    "reframed_test = series_to_supervised(test_data, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jika menggunakan semua parameter\n",
    "# drop columns we don't want to predict\n",
    "reframed_test.drop(reframed_test.columns[[8,9,10,11,12,13]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into input and outputs\n",
    "testX, testY = reframed_test.iloc[:, :-1], reframed_test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view a dimension dataset after supervised learning\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check data train, for result supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_trainX = pd.DataFrame(trainX)\n",
    "temp_trainY = pd.DataFrame(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_train = pd.concat([temp_trainX, temp_trainY], axis=1)\n",
    "hasil_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check data test, for result supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_testX = pd.DataFrame(testX)\n",
    "temp_testY = pd.DataFrame(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_test = pd.concat([temp_testX, temp_testY], axis=1)\n",
    "hasil_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- reshape input for samples, time steps, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data train\n",
    "trainX = np.reshape(np.array(trainX), (trainX.shape[0], 1, trainX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape, trainY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape data test\n",
    "testX = np.reshape(np.array(testX), (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Prediksi Titik Panas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call function\n",
    "from class_base_model import lstm_algorithm\n",
    "from class_base_model import gru_algorithm\n",
    "\n",
    "# check algorithm\n",
    "if algorithm == \"algorithm\":\n",
    "    # call model LSTM-RNN\n",
    "    model = lstm_algorithm(trainX, activation, dropout_rate, optimizer)\n",
    "else:\n",
    "    # call model GRU-RNN\n",
    "    model = gru_algorithm(trainX, activation, dropout_rate, optimizer)\n",
    "\n",
    "# fit network\n",
    "history = model.fit(\n",
    "    trainX, trainY, batch_size=batch_size, epochs=epochs,\n",
    "    validation_data=(testX, testY), verbose=1, shuffle=False, use_multiprocessing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(history.history['loss'], color=\"tab:blue\", label=\"data train\", linewidth=1.5)\n",
    "ax.plot(history.history['val_loss'], color=\"tab:orange\", label=\"data test\", linewidth=1.5)\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(\"Grafik Loss Function\")\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. make predictions\n",
    "predictions = model.predict(testX, verbose=0)\n",
    "print(predictions[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Evaluasi Model LSTM-RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(trainX, trainY)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(testX, testY)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(testY, predictions)\n",
    "print('Test MAE: %.4f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(testY, predictions)\n",
    "print('Test MSE: %.4f' % mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mape = mean_absolute_percentage_error(testY, predictions) * 100\n",
    "print('Test MAPE: %.4f' % mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- korelasi dan signifikansi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil = np.stack((testY,predictions.reshape(-1)),axis=1)\n",
    "hasil = pd.DataFrame(hasil, columns = ['data_aktual','prediksi'])\n",
    "hasil.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sc\n",
    "r, p = sc.pearsonr(hasil[\"data_aktual\"], hasil[\"prediksi\"])\n",
    "print(\"korelasi data akual dengan hasil prediksi\" +\" {:.4f} \".format(r)+ \"dengan signifikansi\" +\" {:.4f} \".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Waktu komputasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set akhir waktu komputasi \n",
    "end = tm.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses menghitung waktu komputasi\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hasil waktu komputasi\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Visualisasi Hasil Prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algorithm == \"LSTM-RNN\":\n",
    "    title = \"Model Stacked-Bidirectional LSTM-RNN\"\n",
    "else:\n",
    "    title = \"Model Stacked-Bidirectional GRU-RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(dataset.iloc[len(train_data)+1:len(dataset),0], testY, color=\"tab:blue\", label=\"data aktual\", linewidth=2)\n",
    "ax.plot(dataset.iloc[len(train_data)+1:len(dataset),0], predictions, color=\"tab:red\", label=\"hasil prediksi\", linewidth=2)\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(title, fontsize=14)\n",
    "ax.set_xlabel(\"\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Hasil Prediksi Titik Panas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(np.array(dataset[[\"hotspot\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse value test predictions\n",
    "testPredictions = scaler.inverse_transform(predictions)\n",
    "testActual = scaler.inverse_transform(np.array(testY).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(np.array(dataset.iloc[train_size+1:len(dataset),0]), columns=['Date'])\n",
    "y = pd.DataFrame(testActual, columns=['Data Aktual'])\n",
    "z = pd.DataFrame(testPredictions, columns=['Data Prediksi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_prediksi = pd.concat([x, y, z], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_prediksi = np.round(hasil_prediksi, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil_prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if algorithm == \"LSTM-RNN\":\n",
    "#     hasil_prediksi.to_csv(\"hasil_prediksi_m1.csv\", index=False)\n",
    "# else:\n",
    "#     hasil_prediksi.to_csv(\"hasil_prediksi_m4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algorithm == \"LSTM-RNN\":\n",
    "    title = \"Model Stacked-Bidirectional LSTM-RNN\"\n",
    "else:\n",
    "    title = \"Model Stacked-Bidirectional GRU-RNN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ax.plot(hasil_prediksi[\"Date\"], hasil_prediksi[\"Data Aktual\"], color=\"tab:blue\", label=\"Data aktual\", linewidth=2.5)\n",
    "ax.plot(hasil_prediksi[\"Date\"], hasil_prediksi[\"Data Prediksi\"], color=\"tab:red\", label=\"Hasil prediksi\", linewidth=2.5)\n",
    "\n",
    "# Mengatur format tanggal ke format tahun\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(title, fontsize=14)\n",
    "ax.set_xlabel(\"\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.legend(loc=\"upper right\")\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "37197ad202cea1caf8a636a74cec7c83b945e4f29ac1505900600f740c02611d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
