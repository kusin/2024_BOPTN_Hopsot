{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter GridSearchCV - Base Model Titik Panas Sumatera Selatan 2001 - 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pustaka manipulasi data array\n",
    "import numpy as np\n",
    "\n",
    "# pustaka manipulasi data frame\n",
    "import pandas as pd\n",
    "import random as rm\n",
    "import time as tm\n",
    "\n",
    "# pustaka untuk visualisasi data\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "# library normalize data with max-min algorithm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# library algorithm lstm-rnn with keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import RNN\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import GRU\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Bidirectional\n",
    "from keras.optimizers import Adam, Adamax, RMSprop, SGD\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# pustaka untuk visualisasi acf dan pacf\n",
    "import scipy.stats as sc\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# pustaka untuk  evaluasi model prediksi\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting seed\n",
    "rm.seed(1234)\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Akuisisi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set waktu komputasi\n",
    "start = tm.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/dataset_hotspot.csv\", parse_dates=[\"acq_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(dataset[\"acq_date\"], dataset[\"hotspot\"], color=\"tab:blue\", label=\"Hotspot di Sumatera Selatan 2001 - 2023\", linewidth=2.5)\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(\"\", fontsize=14)\n",
    "ax.set_xlabel(\"\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. PraProses Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- seleksi fitur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hanya memperhatikan aspek hotspot\n",
    "data = dataset.filter([\"hotspot\"])\n",
    "data = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasil seleksi fitur\n",
    "np.round(data[:5],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek dimensi normalisasi\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Normalisasi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaled = scaler.fit_transform(np.array(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek dimensi normalisasi\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hasil PraProses Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(dataset[\"acq_date\"], np.array(scaled), color=\"tab:blue\", label=\"Hotspot di Sumatera Selatan 2001 - 2023\", linewidth=2.5)\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(\"\", fontsize=14)\n",
    "ax.set_xlabel(\"\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Pembagian Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data train = tahun 2001 - 2018 = 216\n",
    "# data test = tahun 2019 - 2023 = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data train\n",
    "train_size = 216\n",
    "\n",
    "# set loc data train\n",
    "train_data = scaled[0:train_size,:]\n",
    "\n",
    "# show data train\n",
    "np.round(train_data[:5],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dimension of data train\n",
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data test\n",
    "test_size = 60\n",
    "\n",
    "# set loc data test\n",
    "test_data = scaled[train_size:len(scaled),:]\n",
    "\n",
    "# show data test\n",
    "np.round(test_data[:5],7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view dimension of data test\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cek hasil pembagian data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# make a time series plot\n",
    "ax.plot(dataset.iloc[0:len(train_data),0], train_data, color=\"tab:blue\", label=\"Data Train\", linewidth=2.5)\n",
    "ax.plot(dataset.iloc[len(train_data):len(dataset),0], test_data, color=\"tab:red\", label=\"Data Test\", linewidth=2.5)\n",
    "\n",
    "# make are labels\n",
    "# ax.set_title(\"Hotspot Sumsel Sensor MODIS 2001-2020\", fontsize=14)\n",
    "# ax.set_xlabel(\"Years\", fontsize=12)\n",
    "# ax.set_ylabel(\"Sum of hotspot\", fontsize=12)\n",
    "ax.legend(loc=\"best\")\n",
    "ax.grid(True)\n",
    "\n",
    "# show plot time series\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Supervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for supervised learning\n",
    "def create_dataset(look_back, dataset):\n",
    "    \n",
    "    # declare variable X and Y\n",
    "    dataX = []\n",
    "    dataY = []\n",
    "    \n",
    "    # for loop for create supervised learning\n",
    "    for i in range(look_back, len(dataset)):\n",
    "        \n",
    "        # insert value X and Y \n",
    "        dataX.append(dataset[i-look_back:i, 0])\n",
    "        dataY.append(dataset[i, 0])\n",
    "        \n",
    "    # return value X and Y\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set time series lag\n",
    "look_back = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses supervised learning\n",
    "x_train, y_train = create_dataset(look_back, train_data)\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses supervised learning\n",
    "x_test, y_test = create_dataset(look_back, test_data)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- hasil supervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek dimensi data\n",
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Hyperparameter GridSearchCV LSTM-RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- library for hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set models lstm-rnn with sliding windows and timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function models lstm-rnn\n",
    "def get_model(activation='tanh', optimizer='adam', dropout_rate=0.0):\n",
    "    \n",
    "    # reset of session model\n",
    "    tf.keras.backend.clear_session()\n",
    "    \n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    \n",
    "    # first LSTM-RNN layer with dropout regularisation\n",
    "    model.add(LSTM(units=10, activation=activation, input_shape=(x_train.shape[1], 1)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # the output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model predictions\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mae',\n",
    "        metrics=[\n",
    "            tf.keras.metrics.MeanAbsoluteError(),\n",
    "            tf.keras.metrics.MeanSquaredError(),\n",
    "            tf.keras.metrics.MeanAbsolutePercentageError(),\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # return value\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameter\n",
    "- activation function = tanh, sigmoid, relu, selu, softplus, elu.\n",
    "- optimizers = adam, adamax, rmsprop, sgd.\n",
    "- droupout = 0.00, 0.05, 0.1, 0.15, 0.2, 0.25\n",
    "- batch size = 2, 4, 8, 16, 32, 64\n",
    "- epoch = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter activation\n",
    "activation = ['tanh', 'sigmoid', 'relu', 'selu', 'elu', 'softplus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter optimizer\n",
    "optimizer = ['adam', 'adamax', 'rmsprop', 'sgd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter dropout_rate\n",
    "dropout_rate = [0.05, 0.1, 0.15, 0.2, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters batch sizes\n",
    "batch_size = [2, 4, 8, 16, 32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameter epochs\n",
    "epochs = [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set all parameter to dictionary\n",
    "param_grid = dict(\n",
    "    model__activation=activation,\n",
    "    model__optimizer=optimizer,\n",
    "    model__dropout_rate=dropout_rate,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show parameter a gridsearch\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = param_grid.keys()\n",
    "values = (param_grid[key] for key in keys)\n",
    "combinations = [dict(zip(keys, combination)) for combination in itertools.product(*values)]\n",
    "print(len(combinations), str('kombinasi hyperparameter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set grid model with KerasRegressor\n",
    "grid_model = KerasRegressor(model=get_model, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process a gridsearchCV\n",
    "grid_search = GridSearchCV(estimator=grid_model, param_grid=param_grid, n_jobs=4, cv=2, scoring='neg_root_mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show a result gridsearchCV\n",
    "grid_result = grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best parameters: %f using %s\\n\" % (grid_search.best_score_, grid_search.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = grid_search.cv_results_['mean_test_score']\n",
    "stds = grid_search.cv_results_['std_test_score']\n",
    "params = grid_search.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([pd.DataFrame(grid_search.cv_results_[\"params\"]),pd.DataFrame(grid_search.cv_results_[\"mean_test_score\"], columns=[\"score\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.sort_values(by=\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.sort_values(by=\"score\", ascending=False).to_csv('gridsearch_percobaan1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluasi Model Prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- kompleksitas waktu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set akhir waktu komputasi \n",
    "end = tm.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Proses menghitung waktu komputasi\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hasil waktu komputasi\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "37197ad202cea1caf8a636a74cec7c83b945e4f29ac1505900600f740c02611d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
