{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisa Statistik - uji stasioneritas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pustaka untuk manipulasi data\n",
    "import pandas as pd\n",
    "from pandas import concat\n",
    "from pandas import DataFrame\n",
    "from pandas import read_csv\n",
    "from pandas import read_excel\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "\n",
    "# pustaka untuk waktu komputasi\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# Pustaka untuk visualisasi data\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Pustaka untuk visualisasi acf dan pacf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# pustaka normalisasi data / membuat data latih dan data uji.\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from mlxtend.preprocessing import minmax_scaling\n",
    "\n",
    "# pustaka uji stasioneritas statsmodel\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# pustaka uji stasioneritas arch\n",
    "from arch.unitroot import *\n",
    "from arch.unitroot import ADF\n",
    "from arch.unitroot import PhillipsPerron\n",
    "from arch.unitroot import KPSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Akuisisi Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set waktu komputasi\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/dataset_boptn.csv\", parse_dates=[\"acq_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set index tanggal\n",
    "# dataset = dataset.set_index(\"tanggal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Normalisasi Data (Max-Min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memanggil fungsi max min scaler\n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proses max min scaler\n",
    "scaled = scaler.fit_transform(dataset[[\"hotspot\", \"soi_anom\", \"soi_std\", \"sst_anom\", \"sst_std\", \"oni_anom\", \"oni_std\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = pd.DataFrame(scaled)\n",
    "scaled.columns = [\"hotspot\", \"soi_anom\", \"soi_std\", \"sst_anom\", \"sst_std\", \"oni_anom\", \"oni_std\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalisasi = pd.concat([dataset[[\"acq_date\"]], scaled], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "ax.plot(df_normalisasi[\"acq_date\"], df_normalisasi[\"hotspot\"], color=\"tab:blue\", label=\"Data Hostpot 2001 - 2023\", linewidth=2.5)\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(\"Hotspot Sumsel Sensor MODIS 2001-2023\", fontsize=14)\n",
    "ax.set_xlabel(\"\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Plot ACF dan PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "plot_acf(df_normalisasi[\"hotspot\"], lags=24, ax=ax)\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(\"Plot ACF Hotspot Sumsel\", fontsize=14)\n",
    "ax.set_xlabel(\"test\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# membuat frame\n",
    "fig, ax = plt.subplots(figsize = (10,5))\n",
    "\n",
    "# membuat time series plot\n",
    "plot_pacf(df_normalisasi[\"hotspot\"], lags=24, ax=ax)\n",
    "\n",
    "# membuat label-label\n",
    "ax.set_title(\"Plot PACF Hotspot Sumsel\", fontsize=14)\n",
    "ax.set_xlabel(\"test\", fontsize=12)\n",
    "ax.set_ylabel(\"\", fontsize=12)\n",
    "ax.grid(True)\n",
    "\n",
    "# menampilkan plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uji-Stasioneritas (Statsmodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADF Test with statsmodel**\n",
    "- https://machinelearningmastery.com/time-series-data-stationary-python/\n",
    "- https://docs.w3cub.com/statsmodels/generated/statsmodels.tsa.stattools.adfuller\n",
    "- https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula ADF Test\n",
    "# result = adfuller(df_sumsel, maxlag=24, autolag='AIC')\n",
    "result = adfuller(df_normalisasi[\"hotspot\"], autolag=None)\n",
    "\n",
    "# print result ADF Tes \n",
    "print(\"----------------------------------\")\n",
    "print(f'ADF Statistic: {result[0]}')\n",
    "print(f'p-value: {result[1]}')\n",
    "print(f'n-lags: {result[2]}')\n",
    "print(f'n-obs: {result[3]}')\n",
    "\n",
    "print(\"----------------------------------\")\n",
    "print('Critial Values:')\n",
    "for key, value in result[4].items():\n",
    "    print(f'   {key}, {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[1] <= 0.05:\n",
    "    print('Strong evidence against the null hypothesis (Ho), Reject the null hypothesis, Data has no unit root and is stationary')\n",
    "else:\n",
    "    print('Weak evidence against the null hypothesis (Ho), time series has a unit root, indicating it is non stationary.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uji-Stasioneritas (ARCH toolbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ADF Test with ARCH toolbox**\n",
    "- https://arch.readthedocs.io/en/latest/unitroot/generated/arch.unitroot.ADF.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipotesis 0 (H0): data terdapat akar unit. Artinya data bersifat non-stasioner\\\n",
    "Hipotesis 1 (H1): data terdapat tidak akar unit. Artinya data bersifat stasioner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika p-value > 0.05 => Terima H0\\\n",
    "Jika p-value <= 0.05 => Terima H1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adf = ADF(df_normalisasi[\"hotspot\"], lags=15)\n",
    "print(adf.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check linier regression with OLS\n",
    "reg_res = adf.regression\n",
    "print(reg_res.summary().as_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PP Test with ARCH toolbook**\n",
    "- https://arch.readthedocs.io/en/latest/unitroot/generated/arch.unitroot.PhillipsPerron.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipotesis 0 (H0): data terdapat akar unit. Artinya data bersifat non-stasioner\\\n",
    "Hipotesis 1 (H1): data terdapat tidak akar unit. Artinya data bersifat stasioner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jika p-value > 0.05 => Terima H0\\\n",
    "Jika p-value <= 0.05 => Terima H1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = PhillipsPerron(df_normalisasi[\"hotspot\"], lags=15)\n",
    "print(pp.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check linier regression with OLS\n",
    "reg_res = pp.regression\n",
    "print(reg_res.summary().as_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KPSS Test with ARCH toolbook**\n",
    "- https://arch.readthedocs.io/en/latest/unitroot/generated/arch.unitroot.KPSS.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hipotesis 0 (H0): data bersifat stasioner\\\n",
    "Hipotesis 1 (H1): data bersifat non-stasioner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kpss = KPSS(df_normalisasi[\"hotspot\"], lags=15)\n",
    "print(kpss.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "37197ad202cea1caf8a636a74cec7c83b945e4f29ac1505900600f740c02611d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
