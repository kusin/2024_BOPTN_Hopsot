





# library manipulation dataset
import pandas as pd
from pandas import concat
from pandas import DataFrame
from pandas import read_csv
from pandas import read_excel

# library manipulation array
import numpy as np
from numpy import concatenate
from numpy import array

# library configuration date and time
import time
from datetime import datetime

# library data visualization
import seaborn as sns
import matplotlib.dates as mdates
from matplotlib import pyplot
from matplotlib import pyplot as plt

# library analysis acf and pacf
import statsmodels.api as sm
from statsmodels.graphics.tsaplots import plot_pacf
from statsmodels.graphics.tsaplots import plot_acf

# library normalize data with max-min algorithm
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

# library algorithm lstm-rnn with keras
import tensorflow as tf
from tensorflow.keras import models
from keras.models import Sequential
from keras.layers import RNN
from keras.layers import LSTM
from keras.layers import GRU
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import TimeDistributed
from keras.layers import Bidirectional
from keras.optimizers import Adam, Adamax, RMSprop, SGD
from keras.layers import LeakyReLU

# Early stoping
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint

# library evaluation model
from math import sqrt
from sklearn.metrics import make_scorer
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error





# Set waktu komputasi
start = time.time()


# fix random seed for reproducibility
np.random.seed(1234)


# membaca dataset
dataset = read_excel("dataset/dataset.xlsx")


# set index tanggal
dataset = dataset.set_index("tanggal")


# menampilkan metadata dataset
dataset.info()


print(dataset.head())








# make frame
fig, ax = plt.subplots(figsize = (20,6))

# make time series plot
ax.plot(dataset.index, dataset["hotspot_sumsel"], color="tab:blue", label="hotspot sumsel 2001-2020", linewidth=2.5)

# make are labels
ax.set_title("Hotspot Sumsel 2001-2020", fontsize=14)
ax.set_xlabel("Year", fontsize=12)
ax.set_ylabel("Sum of hostpot", fontsize=12)
ax.legend(loc='best')
ax.grid(True)

# show plot time series
plt.show()





# make frame
fig, ax= plt.subplots(nrows=1, ncols=2, facecolor="#F0F0F0", figsize = (20,5))

# plot acf
plot_acf(dataset["hotspot_sumsel"], lags=24, ax=ax[0])
ax[0].grid(True)

# plot pacf
plot_pacf(dataset["hotspot_sumsel"],lags=24, ax=ax[1], method="yw")
ax[1].grid(True)

# show plot acf and pacf
plt.show()








# memilih area studi
df_sumsel = dataset[["hotspot_sumsel", "curah_hujan"]]


# ensure all data is float
df_sumsel = df_sumsel.values
df_sumsel = df_sumsel.astype('float64')


# show a dataset
np.round(df_sumsel[:5],4)


# view a dimension dataset
df_sumsel.shape


# membuat frame
fig, ((ax1, ax2)) = plt.subplots(nrows=1, ncols=2, facecolor="#f0f0f0", figsize=(20, 5))
# ----------------------------------------------------------------------------------------------------

# make time series plot
ax1.plot(dataset.index, df_sumsel[:,0:1], color="tab:blue", label="hotspot sumsel 2001-2020", linewidth=2.5)

# make are labels
ax1.set_title("Hotspot Sumsel 2001-2020", fontsize=14)
ax1.set_xlabel("Year", fontsize=12)
ax1.set_ylabel("Sum of hostpot", fontsize=12)
ax1.legend(loc='best')
ax1.grid(True)
# ----------------------------------------------------------------------------------------------------

# make time series plot
ax2.plot(dataset.index, df_sumsel[:,1:2], color="tab:blue", label="curah hujan sumsel 2001-2020", linewidth=2.5)

# make are labels
ax2.set_title("Curah Hujan Sumsel 2001-2020", fontsize=14)
ax2.set_xlabel("Year", fontsize=12)
ax2.set_ylabel("Sum of rainfall", fontsize=12)
ax2.legend(loc='best')
ax2.grid(True)
# ----------------------------------------------------------------------------------------------------

# set the spacing between subplots
plt.subplots_adjust(wspace=0.12, hspace=0.25)

# show plot time series
plt.show()





# normalize features
scaler = MinMaxScaler(feature_range=(-1, 1))
df_sumsel = scaler.fit_transform(df_sumsel)


np.round(df_sumsel[:5],4)


# view a dimension dataset after normalize
df_sumsel.shape


# membuat frame
fig, ((ax1, ax2)) = plt.subplots(nrows=1, ncols=2, facecolor="#f0f0f0", figsize=(20, 5))
# ----------------------------------------------------------------------------------------------------

# make time series plot
ax1.plot(dataset.index, df_sumsel[:,0:1], color="tab:blue", label="hotspot sumsel 2001-2020", linewidth=2.5)

# make are labels
ax1.set_title("Hotspot Sumsel 2001-2020", fontsize=14)
ax1.set_xlabel("Year", fontsize=12)
ax1.set_ylabel("Sum of hostpot", fontsize=12)
ax1.legend(loc='best')
ax1.grid(True)
# ----------------------------------------------------------------------------------------------------

# make time series plot
ax2.plot(dataset.index, df_sumsel[:,1:2], color="tab:blue", label="curah hujan sumsel 2001-2020", linewidth=2.5)

# make are labels
ax2.set_title("Curah Hujan Sumsel 2001-2020", fontsize=14)
ax2.set_xlabel("Year", fontsize=12)
ax2.set_ylabel("Sum of rainfall", fontsize=12)
ax2.legend(loc='best')
ax2.grid(True)
# ----------------------------------------------------------------------------------------------------

# set the spacing between subplots
plt.subplots_adjust(wspace=0.12, hspace=0.25)

# show plot time series
plt.show()





# set data train
train_size = int(len(df_sumsel) * 0.8)


# set loc data train
train = df_sumsel[0:train_size,:]


# show data train
np.round(train[:5],4)


# view dimension of data train
train.shape


# set data test
test_size = len(df_sumsel) - train_size


# set loc data test
test = df_sumsel[train_size:len(df_sumsel),:]


# show data test
np.round(test[:5],4)


# view dimension of data test
test.shape


# membuat frame
fig, ((ax1, ax2)) = plt.subplots(nrows=1, ncols=2, facecolor="#f0f0f0", figsize=(20, 5))
# ----------------------------------------------------------------------------------------------------

# make time series plot
ax1.plot(
    dataset.iloc[0:train_size].index, train[:,0:1],
    color="tab:blue", label="data latih", linewidth=2.5
)
ax1.plot(
    dataset.iloc[train_size:len(dataset)].index, test[:,0:1],
    color="tab:red", label="data uji", linewidth=2.5
)

# make are labels
ax1.set_title("Hotspot Sumsel Sensor MODIS 2001-2020", fontsize=14)
ax1.set_xlabel("Year", fontsize=12)
ax1.set_ylabel("Sum of Hostpot", fontsize=12)
ax1.legend(loc="best")
ax1.grid(True)
# ----------------------------------------------------------------------------------------------------

# make time series plot
ax2.plot(
    dataset.iloc[0:train_size].index, train[:,1:2],
    color="tab:blue", label="data latih", linewidth=2.5
)
ax2.plot(
    dataset.iloc[train_size:len(dataset)].index, test[:,1:2],
    color="tab:red", label="data uji", linewidth=2.5
)

# make are labels
ax2.set_title("Curah Hujan Sumsel 2001-2020", fontsize=14)
ax2.set_xlabel("Year", fontsize=12)
ax2.set_ylabel("Sum of rainfall", fontsize=12)
ax2.legend(loc='best')
ax2.grid(True)
# ----------------------------------------------------------------------------------------------------

# set the spacing between subplots
plt.subplots_adjust(wspace=0.12, hspace=0.25)

# show plot time series
plt.show()





# convert series to supervised learning
def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):
    n_vars = 1 if type(data) is list else data.shape[1]
    df = DataFrame(data)
    cols, names = list(), list()
    
    # input sequence (t-n, ... t-1)
    for i in range(n_in, 0, -1):
        cols.append(df.shift(i))
        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]
    
    # forecast sequence (t, t+1, ... t+n)
    for i in range(0, n_out):
        cols.append(df.shift(-i))
        if i == 0:
            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]
        else:
            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]
    
    # put it all together
    agg = concat(cols, axis=1)
    agg.columns = names
    
    # drop rows with NaN values
    if dropnan:
        agg.dropna(inplace=True)
    
    # return value
    return agg





# set supervised learning for data train
reframed_train = series_to_supervised(train, 1, 1)


# drop columns we don't want to predict
reframed_train.drop(reframed_train.columns[[3]], axis=1, inplace=True)


# split into input and outputs
trainX, trainY = reframed_train.iloc[:, :-1], reframed_train.iloc[:, -1]


# view a dimension dataset after supervised learning
print(trainX.shape, trainY.shape)


# set supervised learning for data test
reframed_test = series_to_supervised(test, 1, 1)


# drop columns we don't want to predict
reframed_test.drop(reframed_test.columns[[3]], axis=1, inplace=True)


# split into input and outputs
testX, testY = reframed_test.iloc[:, :-1], reframed_test.iloc[:, -1]


# view a dimension dataset after supervised learning
print(testX.shape, testY.shape)





temp_trainX = pd.DataFrame(trainX)
temp_trainY = pd.DataFrame(trainY)


hasil_train = pd.concat([temp_trainX, temp_trainY], axis=1)
hasil_train.info()


hasil_train.head()





temp_testX = pd.DataFrame(testX)
temp_testY = pd.DataFrame(testY)


hasil_test = pd.concat([temp_testX, temp_testY], axis=1)
hasil_test.info()


hasil_test.head()





# reshape data train
trainX = np.reshape(np.array(trainX), (trainX.shape[0], 1, trainX.shape[1]))


print(trainX.shape, trainY.shape)


# reshape data test
testX = np.reshape(np.array(testX), (testX.shape[0], 1, testX.shape[1]))


print(testX.shape, testY.shape)








# reset of session model
tf.keras.backend.clear_session()

# design network grid serach
model = Sequential()

# first lstm-rnn layer with dropout regularisation
model.add(
    LSTM(
        units=10,
        activation="selu",
        input_shape=(trainX.shape[1], trainX.shape[2])
    )
)
model.add(Dropout(0.20))

# the output layer
model.add(Dense(1))

# model compile
model.compile(
    optimizer="rmsprop",
    loss="mae",
    metrics=[
        tf.keras.metrics.MeanAbsoluteError(),
        tf.keras.metrics.MeanSquaredError(),
        tf.keras.metrics.RootMeanSquaredError()
    ]
)


# fit network
history = model.fit(trainX, trainY, epochs=2000, batch_size=32,
                    validation_data=(testX, testY), use_multiprocessing=True,
                    verbose=0, shuffle=False)


model.summary()


# membuat frame
fig, ax = plt.subplots(figsize = (8,4))

# membuat time series plot
ax.plot(history.history['loss'], color="tab:blue", label="data train", linewidth=1.5)
ax.plot(history.history['val_loss'], color="tab:orange", label="data test", linewidth=1.5)

# membuat label-label
ax.set_title("Grafik Loss Function")
ax.legend(loc='upper right')
ax.grid(True)

# menampilkan plot
plt.show()


# 5. make predictions
predictions = model.predict(testX, verbose=0)
print(predictions[:, 0])





scores = model.evaluate(trainX, trainY)
scores


scores = model.evaluate(testX, testY)
scores





mae = mean_absolute_error(testY, predictions)
print('Test MAE: %.4f' % mae)





mse = mean_squared_error(testY, predictions)
print('Test MSE: %.4f' % mse)





# calculate RMSE
rmse = sqrt(mean_squared_error(testY , predictions))
print('Test RMSE: %.4f' % rmse)





mape = mean_absolute_percentage_error(testY, predictions)
print('Test MAPE: %.4f' % mape)





# smape = sMAPE(np.array(testY), np.array(predictions))
# print('Test sMAPE: %.4f' % smape)





hasil = np.stack((testY,predictions.reshape(-1)),axis=1)
hasil = pd.DataFrame(hasil, columns = ['data_aktual','prediksi'])
hasil.head()


import scipy.stats as sc
r, p = sc.pearsonr(hasil["data_aktual"], hasil["prediksi"])
print("korelasi data akual dengan hasil prediksi" +" {:.4f} ".format(r)+ "dengan signifikansi" +" {:.4f} ".format(p))





# Set akhir waktu komputasi 
end = time.time()


# Proses menghitung waktu komputasi
hours, rem = divmod(end-start, 3600)
minutes, seconds = divmod(rem, 60)


# Hasil waktu komputasi
print("{:0>2}:{:0>2}:{:05.2f}".format(int(hours),int(minutes),seconds))





# generate urutan data sesuai panjang datanya
x = pd.date_range(start="2017-01-01", periods=len(testY), freq='MS')

# membuat frame
fig, ax = plt.subplots(figsize = (8,4))

# membuat time series plot
ax.plot(x, testY, color="tab:blue", label="data aktual", linewidth=2.5)
ax.plot(x, predictions, color="tab:red", label="hasil prediksi", linewidth=2.5)

# membuat label-label
ax.xaxis.set_major_locator(mdates.YearLocator())
ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
ax.legend(loc='upper right')
ax.grid(True)

# menampilkan plot
plt.show()





df_sumsel = np.array(dataset["hotspot_sumsel"])


scaler = MinMaxScaler(feature_range=(-1,1))
df_sumsel = scaler.fit_transform(df_sumsel.reshape(-1,1))


# inverse value test predictions
testPredictions = scaler.inverse_transform(predictions)
testActual = scaler.inverse_transform(np.array(testY).reshape(-1, 1))


# generate urutan data sesuai panjang datanya
x = pd.date_range(start="2017-01-01", periods=len(testY), freq='MS')

# membuat frame
fig, ax = plt.subplots(figsize = (8,4))

# membuat time series plot
ax.plot(x, testActual, color="tab:blue", label="Actual data", linewidth=2.5)
ax.plot(x, testPredictions, color="tab:red", label="Prediction results", linewidth=2.5)

# membuat label-label
ax.xaxis.set_major_locator(mdates.YearLocator())
ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
ax.legend(loc="best")
ax.grid(True)

# menampilkan plot
plt.show()


#  shift test predictions for plotting
testPredictionsPlot = np.empty_like(df_sumsel)
testPredictionsPlot[:, :] = np.nan
testPredictionsPlot[(len(dataset) - testPredictions.shape[0]):len(dataset), :] = testPredictions


# membuat frame
fig, ax = plt.subplots(figsize = (10,5))

# membuat time series plot
ax.plot(dataset.index.values, scaler.inverse_transform(df_sumsel), color="tab:blue", label="actual data", linewidth=2)
ax.plot(dataset.index.values, testPredictionsPlot, color="tab:red", label="predictions data", linewidth=2)

# membuat label-label
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
ax.legend(loc="best")
ax.grid(True)

# menampilkan plot
plt.show()





import xgboost as xgb


# Calculate residuals (difference between LSTM predictions and actual values)
residuals = testY - predictions[:, 0]


# Train XGBoost model on residuals
xgb_model = xgb.XGBRegressor()
xgb_model.fit(np.vstack(testX), residuals)


# Predict residuals with XGBoost model
xgb_predictions = xgb_model.predict(np.vstack(testX))


# Combine LSTM and XGBoost predictions
boosted_predictions = predictions[:, 0] + xgb_predictions


# Use boosted_predictions as the final predictions
print(boosted_predictions)





mae = mean_absolute_error(testY, boosted_predictions)
print('Test MAE : %.4f' % mae)


mse = mean_squared_error(testY, boosted_predictions)
print('Test MSE: %.4f' % mse)


# calculate RMSE
rmse = sqrt(mse)
print('Test RMSE: %.4f' % rmse)


mape = mean_absolute_percentage_error(testY, boosted_predictions)
print('Test MAPE: %.4f' % mape)


hasil = np.stack((testY, boosted_predictions), axis=1)
hasil = pd.DataFrame(hasil, columns = ['data_aktual','prediksi'])
hasil.head()


import scipy.stats as sc
r, p = sc.pearsonr(hasil["data_aktual"], hasil["prediksi"])
print("korelasi data akual dengan hasil prediksi" +" {:.4f} ".format(r)+ "dengan signifikansi" +" {:.4f} ".format(p))





df_sumsel = np.array(dataset["hotspot_sumsel"])


scaler = MinMaxScaler(feature_range=(-1,1))
df_sumsel = scaler.fit_transform(df_sumsel.reshape(-1,1))


# inverse value test predictions
testPredictions = scaler.inverse_transform(boosted_predictions.reshape(-1, 1))
testActual = scaler.inverse_transform(np.array(testY).reshape(-1, 1))


# generate urutan data sesuai panjang datanya
x = pd.date_range(start="2017-01-01", periods=len(testY), freq='MS')

# membuat frame
fig, ax = plt.subplots(figsize = (10,5))

# membuat time series plot
ax.plot(x, testActual, color="tab:blue", label="Actual data", linewidth=2.5)
ax.plot(x, testPredictions, color="tab:red", label="Prediction results", linewidth=2.5)

# membuat label-label
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
ax.legend(loc="best")
ax.grid(True)

# menampilkan plot
plt.show()


#  shift test predictions for plotting
testPredictionsPlot = np.empty_like(df_sumsel)
testPredictionsPlot[:, :] = np.nan
testPredictionsPlot[(len(dataset) - testPredictions.shape[0]):len(dataset), :] = testPredictions


# membuat frame
fig, ax = plt.subplots(figsize = (10,5))

# membuat time series plot
ax.plot(dataset.index.values, scaler.inverse_transform(df_sumsel), color="tab:blue", label="actual data", linewidth=2)
ax.plot(dataset.index.values, testPredictionsPlot, color="tab:red", label="predictions data", linewidth=2)

# membuat label-label
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
ax.legend(loc="best")
ax.grid(True)

# menampilkan plot
plt.show()


hasil_prediksi = pd.concat([pd.DataFrame(testActual,columns=['Data Aktual']), pd.DataFrame(testPredictions,columns=['Hasil Prediksi'])], axis=1)


hasil_prediksi.to_excel("hasil_percobaan2.xlsx", index=False)



