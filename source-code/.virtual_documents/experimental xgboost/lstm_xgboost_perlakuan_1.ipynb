





# library manipulation dataset
import pandas as pd
from pandas import concat
from pandas import DataFrame
from pandas import read_csv
from pandas import read_excel

# library manipulation array
import numpy as np
from numpy import concatenate
from numpy import array

# library configuration date and time
import time
from datetime import datetime

# library data visualization
import seaborn as sns
import matplotlib.dates as mdates
from matplotlib import pyplot
from matplotlib import pyplot as plt

# library analysis acf and pacf
import statsmodels.api as sm
from statsmodels.graphics.tsaplots import plot_pacf
from statsmodels.graphics.tsaplots import plot_acf

# library normalize data with max-min algorithm
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

# library algorithm lstm-rnn with keras
import tensorflow as tf
from keras.models import Sequential
from keras.layers import RNN
from keras.layers import LSTM
from keras.layers import GRU
from keras.layers import Dense
from keras.layers import Dropout
from keras.layers import TimeDistributed
from keras.layers import Bidirectional
from keras.optimizers import Adam, Adamax, RMSprop, SGD
from keras.layers import LeakyReLU
# library untuk model ensambel
from sklearn.ensemble import VotingClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import StackingClassifier

# Early stoping
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint

# library evaluation model
from math import sqrt
from sklearn.metrics import make_scorer
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_absolute_percentage_error





# Set waktu komputasi
start = time.time()


# fix random seed for reproducibility
np.random.seed(1234)


# membaca dataset
dataset = read_excel("dataset/dataset.xlsx")


# # set index tanggal
# dataset = dataset.set_index("tanggal")


# menampilkan metadata dataset
dataset.info()


dataset.describe()


print(dataset.head())








# make frame
fig, ax = plt.subplots(figsize = (20,6))

# make time series plot
ax.plot(dataset["tanggal"], dataset["hotspot_sumsel"], color="tab:blue", label="hotspot sumsel 2001-2020", linewidth=2.5)

# make are labels
ax.set_title("Hotspot Sumsel 2001-2020", fontsize=14)
ax.set_xlabel("Date", fontsize=12)
ax.set_ylabel("Sum of hostpot", fontsize=12)
ax.legend(loc='best')
ax.grid(True)

# show plot time series
plt.show()





# make frame
fig, ax= plt.subplots(nrows=1, ncols=2, facecolor="#F0F0F0", figsize = (20,5))

# plot acf
plot_acf(dataset["hotspot_sumsel"], lags=24, ax=ax[0])
ax[0].grid(True)

# plot pacf
plot_pacf(dataset["hotspot_sumsel"],lags=24, ax=ax[1], method="yw")
ax[1].grid(True)

# show plot acf and pacf
plt.show()








# memilih area studi
df_sumsel = dataset[["hotspot_sumsel"]]


# ensure all data is float
df_sumsel = df_sumsel.values
df_sumsel = df_sumsel.astype('float64');


# show a dataset
np.round(df_sumsel[:5],4)


# view a dimension dataset
df_sumsel.shape


# membuat frame
fig, ax = plt.subplots(figsize = (20,6))

# membuat time series plot
ax.plot(dataset["tanggal"], df_sumsel, color="tab:blue", label="hotspot sumsel 2001-2020", linewidth=2.5)

# membuat label-label
ax.set_title("Hotspot Sumsel Sensor MODIS 2001-2020", fontsize=14)
ax.set_xlabel("Tanggal", fontsize=12)
ax.set_ylabel("Jumlah Hostpot", fontsize=12)
ax.legend(loc='upper right')
ax.grid(True)

# menampilkan plot
plt.show()





# normalize features
scaler = MinMaxScaler(feature_range=(-1,1))
df_sumsel = scaler.fit_transform(df_sumsel)


np.round(df_sumsel[:5],6)


# view a dimension dataset after normalize
df_sumsel.shape


# membuat frame
fig, ax = plt.subplots(figsize = (20,5))

# membuat time series plot
ax.plot(dataset["tanggal"], df_sumsel, color="tab:blue", label="data aktual", linewidth=2.5)

# membuat label-label
ax.set_title("Hotspot Sumsel Sensor MODIS 2001-2020", fontsize=14)
ax.set_xlabel("Tanggal", fontsize=12)
ax.set_ylabel("Jumlah Hostpot", fontsize=12)
ax.legend(loc='upper right')
ax.grid(True)

# menampilkan plot
plt.show()





# set data train
train_size = int(len(df_sumsel) * 0.8)


# set loc data train
train = df_sumsel[0:train_size,:]


# show data train
np.round(train[:5],4)


# view dimension of data train
train.shape


# set data test
test_size = len(df_sumsel) - train_size


# set loc data test
test = df_sumsel[train_size:len(df_sumsel),:]


# show data test
np.round(test[:5],4)


# view dimension of data test
test.shape


# make a frame
fig, ax = plt.subplots(figsize = (15,5))

# make a time series plot
ax.plot(dataset.iloc[0:train_size,0], train, color="tab:blue", label="data train", linewidth=2.5)
ax.plot(dataset.iloc[train_size:len(dataset),0], test, color="tab:red", label="data test", linewidth=2.5)

# make are labels
# ax.set_title("Hotspot Sumsel Sensor MODIS 2001-2020", fontsize=14)
# ax.set_xlabel("Years", fontsize=12)
# ax.set_ylabel("Sum of hotspot", fontsize=12)
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
ax.legend(loc="best")
ax.grid(True)

# show plot time series
plt.show()





# function for supervised learning
def create_dataset(dataset, look_back=1):
    
    # declare variable X and Y
    dataX = []
    dataY = []
    
    # for loop for create supervised learning
    for i in range(len(dataset)-look_back):
        
        # insert value X and Y 
        dataX.append(dataset[i:(i+look_back), 0])
        dataY.append(dataset[i + look_back, 0])
    
    # return value X and Y
    return np.array(dataX), np.array(dataY)





# set look back -1
look_back = 1


# set supervised learning for data train
trainX, trainY = create_dataset(train, look_back)


# view a dimension dataset after supervised learning
print(trainX.shape, trainY.shape)


# set supervised learning for data test
testX, testY = create_dataset(test, look_back)


# view a dimension dataset after supervised learning
print(testX.shape, testY.shape)





temp_trainX = pd.DataFrame(trainX, columns=['x train'])
temp_trainY = pd.DataFrame(trainY, columns=['y train'])


hasil_train = pd.concat([temp_trainX, temp_trainY], axis=1)
hasil_train.info()


hasil_train.head()





temp_testX = pd.DataFrame(testX, columns=['x test'])
temp_testY = pd.DataFrame(testY, columns=['y test'])


hasil_test = pd.concat([temp_testX, temp_testY], axis=1)
hasil_test.info()


hasil_test.head()





# reshape data train
trainX = np.reshape(trainX, (trainX.shape[0], trainX.shape[1], 1))


print(trainX.shape, trainY.shape)


# reshape data test
testX = np.reshape(testX, (testX.shape[0], testX.shape[1], 1))


print(testX.shape, testY.shape)





# Design network
model = Sequential()

# First LSTM layer with Dropout regularisation
model.add(
    LSTM(
        units=10,
        activation="selu",
        input_shape=(trainX.shape[1], 1)
    )
)
model.add(Dropout(0.20))

# The output layer
model.add(Dense(1))

# Compiling model the LSTM-RNN
model.compile(
    optimizer='sgd',
    loss='mae',
    metrics=[
        tf.keras.metrics.MeanAbsoluteError(),
        tf.keras.metrics.MeanSquaredError(),
        tf.keras.metrics.RootMeanSquaredError()
    ]
)


# fit network
history = model.fit(trainX, trainY, epochs=2000, batch_size=8,
                    validation_data=(testX, testY),
                    verbose=0, shuffle=False)


model.summary()


# membuat frame
fig, ax = plt.subplots(figsize = (10,5))

# membuat time series plot
ax.plot(history.history['loss'], color="tab:blue", label="data train", linewidth=2)
ax.plot(history.history['val_loss'], color="tab:orange", label="data test", linewidth=2)

# membuat label-label
ax.set_title("Grafik Loss Function")
ax.legend(loc="best")
ax.grid(True)

# menampilkan plot
plt.show()


# 5. make predictions
predictions = model.predict(testX, verbose=0)
print(predictions[:, 0])





scores = model.evaluate(trainX, trainY)
scores


scores = model.evaluate(testX, testY)
scores





mae = mean_absolute_error(testY, predictions)
print('Test MAE : %.4f' % mae)





mse = mean_squared_error(testY, predictions)
print('Test MSE: %.4f' % mse)





# calculate RMSE
rmse = sqrt(mse)
print('Test RMSE: %.4f' % rmse)





mape = mean_absolute_percentage_error(testY, predictions)
print('Test MAPE: %.4f' % mape)





hasil = np.stack((testY.reshape(-1), predictions.reshape(-1)), axis=1)
hasil = pd.DataFrame(hasil, columns = ['data_aktual','prediksi'])
hasil.head()


import scipy.stats as sc
r, p = sc.pearsonr(hasil["data_aktual"], hasil["prediksi"])
print("korelasi data akual dengan hasil prediksi" +" {:.4f} ".format(r)+ "dengan signifikansi" +" {:.4f} ".format(p))





# Set akhir waktu komputasi 
end = time.time()


# Proses menghitung waktu komputasi
hours, rem = divmod(end-start, 3600)
minutes, seconds = divmod(rem, 60)


# Hasil waktu komputasi
print("{:0>2}:{:0>2}:{:05.2f}".format(int(hours),int(minutes),seconds))





# generate urutan data sesuai panjang datanya
x = pd.date_range(start="2017-01-01", periods=len(testY), freq='MS')

# membuat frame
fig, ax = plt.subplots(figsize = (8,4))

# membuat time series plot
ax.plot(x, testY, color="tab:blue", label="actual data", linewidth=2.5)
ax.plot(x, predictions, color="tab:red", label="prediction data", linewidth=2.5)

# membuat label-label
ax.xaxis.set_major_locator(mdates.YearLocator())
ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
ax.legend(loc="best")
ax.grid(True)

# menampilkan plot
plt.show()


# inverse value test predictions
testPredictions = scaler.inverse_transform(predictions)
testActual = scaler.inverse_transform(testY.reshape(-1, 1))


x = pd.DataFrame(np.array(dataset.iloc[train_size+1:len(dataset),0]), columns=['Date'])
y = pd.DataFrame(testActual, columns=['Data Aktual'])
z = pd.DataFrame(testPredictions, columns=['Data Prediksi'])


hasil_prediksi = pd.concat([x, y, z], axis=1)
hasil_prediksi.tail()


fix, ax = plt.subplots(figsize=(8,4))

ax.plot(hasil_prediksi["Date"], hasil_prediksi["Data Aktual"], color="tab:blue", label="actual data", linewidth=2.5)
ax.plot(hasil_prediksi["Date"], hasil_prediksi["Data Prediksi"], color="tab:red", label="prediction data", linewidth=2.5)

# Mengatur format tanggal ke format tahun
ax.xaxis.set_major_locator(mdates.YearLocator())
ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))

# membuat label-label
ax.legend(loc="best")
ax.grid(True)

# menampilkan plot
plt.show()


#  shift test predictions for plotting
testPredictionsPlot = np.empty_like(df_sumsel)
testPredictionsPlot[:, :] = np.nan
testPredictionsPlot[(len(dataset) - testPredictions.shape[0]):len(dataset), :] = testPredictions


# membuat frame
fig, ax = plt.subplots(figsize = (8,4))

# membuat time series plot
ax.plot(dataset["tanggal"], scaler.inverse_transform(df_sumsel), color="tab:blue", label="actual data", linewidth=2)
ax.plot(dataset["tanggal"], testPredictionsPlot, color="tab:red", label="predictions data", linewidth=2)

# membuat label-label
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
ax.legend(loc="best")
ax.grid(True)

# menampilkan plot
plt.show()





import xgboost as xgb


# Calculate residuals (difference between LSTM predictions and actual values)
residuals = testY - predictions[:, 0]


# Train XGBoost model on residuals
xgb_model = xgb.XGBRegressor()
xgb_model.fit(np.vstack(testX), residuals)


# Predict residuals with XGBoost model
xgb_predictions = xgb_model.predict(np.vstack(testX))



# Combine LSTM and XGBoost predictions
boosted_predictions = predictions[:, 0] + xgb_predictions


# Use boosted_predictions as the final predictions
print(boosted_predictions)





mae = mean_absolute_error(testY, boosted_predictions)
print('Test MAE : %.4f' % mae)


mse = mean_squared_error(testY, boosted_predictions)
print('Test MSE: %.4f' % mse)


# calculate RMSE
rmse = sqrt(mse)
print('Test RMSE: %.4f' % rmse)


mape = mean_absolute_percentage_error(testY, boosted_predictions)
print('Test MAPE: %.4f' % mape)


hasil = np.stack((testY.reshape(-1), boosted_predictions.reshape(-1)), axis=1)
hasil = pd.DataFrame(hasil, columns = ['data_aktual','prediksi'])
hasil.head()


import scipy.stats as sc
r, p = sc.pearsonr(hasil["data_aktual"], hasil["prediksi"])
print("korelasi data akual dengan hasil prediksi" +" {:.4f} ".format(r)+ "dengan signifikansi" +" {:.4f} ".format(p))





# inverse value test predictions
testPredictions = scaler.inverse_transform(boosted_predictions.reshape(-1, 1))
testActual = scaler.inverse_transform(testY.reshape(-1, 1))


# generate urutan data sesuai panjang datanya
x = pd.date_range(start="2017-01-01", periods=len(testY), freq='MS')

# membuat frame
fig, ax = plt.subplots(figsize = (10,5))

# membuat time series plot
ax.plot(x, testActual, color="tab:blue", label="Actual data", linewidth=2.5)
ax.plot(x, testPredictions, color="tab:red", label="Prediction results", linewidth=2.5)

# membuat label-label
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
ax.legend(loc="best")
ax.grid(True)

# menampilkan plot
plt.show()


#  shift test predictions for plotting
testPredictionsPlot = np.empty_like(df_sumsel)
testPredictionsPlot[:, :] = np.nan
testPredictionsPlot[(len(dataset) - testPredictions.shape[0]):len(dataset), :] = testPredictions


# membuat frame
fig, ax = plt.subplots(figsize = (10,5))

# membuat time series plot
ax.plot(dataset["tanggal"], scaler.inverse_transform(df_sumsel), color="tab:blue", label="actual data", linewidth=2)
ax.plot(dataset["tanggal"], testPredictionsPlot, color="tab:red", label="predictions data", linewidth=2)

# membuat label-label
ax.xaxis.set_major_formatter(mdates.DateFormatter('%b-%Y'))
ax.legend(loc="best")
ax.grid(True)

# menampilkan plot
plt.show()


hasil_prediksi = pd.concat([pd.DataFrame(testActual,columns=['Data Aktual']), pd.DataFrame(testPredictions,columns=['Hasil Prediksi'])], axis=1)


hasil_prediksi.to_excel("hasil_percobaan1.xlsx", index=False)






